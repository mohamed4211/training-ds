{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "# Data Visualizations\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "sns.set(font_scale= 2)\r\n",
    "\r\n",
    "import re\r\n",
    "import string\r\n",
    "import os\r\n",
    "from tqdm import tqdm as tq\r\n",
    "import time\r\n",
    "\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "from torch.utils.data import DataLoader, ConcatDataset\r\n",
    "from torchvision import transforms, datasets, models\r\n",
    "from PIL import Image\r\n",
    "\r\n",
    "from sklearn import model_selection\r\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T12:46:22.108727Z",
     "iopub.status.busy": "2021-08-12T12:46:22.108151Z",
     "iopub.status.idle": "2021-08-12T12:46:32.299625Z",
     "shell.execute_reply": "2021-08-12T12:46:32.298503Z",
     "shell.execute_reply.started": "2021-08-12T12:46:22.108691Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Device"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "if torch.cuda.is_available():\r\n",
    "    print(f\"GPU:{torch.cuda.get_device_name()}\")\r\n",
    "    DEVICE = torch.device('cuda')\r\n",
    "else:\r\n",
    "    DEVICE = torch.device('cpu')\r\n",
    "    print(DEVICE)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T12:46:32.301615Z",
     "iopub.status.busy": "2021-08-12T12:46:32.301345Z",
     "iopub.status.idle": "2021-08-12T12:46:32.308967Z",
     "shell.execute_reply": "2021-08-12T12:46:32.307993Z",
     "shell.execute_reply.started": "2021-08-12T12:46:32.301588Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Helper Methods"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "\r\n",
    "def remainig_time(tt):\r\n",
    "    if tt/60 < 1:\r\n",
    "        return \"{} sec\".format(int(tt))\r\n",
    "    if tt/60/60 < 1:\r\n",
    "        return \"{} min\".format(int(tt/60))\r\n",
    "    if tt/60/60/24 < 1:\r\n",
    "        mins = tt/60\r\n",
    "        hrs = mins/60\r\n",
    "        return \"{:.2f} hrs\".format(hrs)\r\n",
    "    if tt/60/60/24 > 1:\r\n",
    "        days = tt/60/60/24\r\n",
    "        return \"{:.2f} days\".format(days)\r\n",
    "\r\n",
    "\r\n",
    "def save_model(model, optim, loss_train, loss_val, acc_train, acc_val, epoch, model_name, model_path=''):\r\n",
    "    torch.save({\r\n",
    "        'model_state_dict': model.state_dict(),\r\n",
    "        'optimizer_state_dict': optim.state_dict(),\r\n",
    "        'loss_train': loss_train,\r\n",
    "        'loss_val': loss_val,\r\n",
    "        'epoch': epoch,\r\n",
    "        'acc_train': acc_train,\r\n",
    "        'acc_val': acc_val,\r\n",
    "    }, os.path.join(model_path, model_name))\r\n",
    "\r\n",
    "\r\n",
    "def load_model(model_path, device=DEVICE):\r\n",
    "    return torch.load(model_path, map_location=device)"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T12:46:32.310759Z",
     "iopub.status.busy": "2021-08-12T12:46:32.310467Z",
     "iopub.status.idle": "2021-08-12T12:46:32.336422Z",
     "shell.execute_reply": "2021-08-12T12:46:32.335403Z",
     "shell.execute_reply.started": "2021-08-12T12:46:32.310731Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Constants"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Hyper Parameters (You can change as you like ... and see how it affects the results)\r\n",
    "LR = 3e-5\r\n",
    "BATCH_SIZE = 32\r\n",
    "IMG_WIDTH = 224\r\n",
    "IMG_HEIGHT = 224\r\n",
    "IMG_RESIZE = (IMG_HEIGHT, IMG_WIDTH)\r\n",
    "EPOCHS = 100\r\n",
    "# Constants\r\n",
    "NUM_WORKERS = 3 # Based on the \r\n",
    "NUM_CLASSES = 2\r\n",
    "CLASSES = ['NORMAL', 'PNEUMONIA']\r\n",
    "CHANNELS = 1\r\n",
    "MIN_ACC = float('-inf')\r\n",
    "# Data Path\r\n",
    "DATA_PATH = 'C:/Users/20106/Desktop/Practical-DS-Session-main/Pneumonia/chest_xray/'\r\n",
    "TRAIN_DATA_PATH = os.path.join(DATA_PATH, 'train/')\r\n",
    "VAL_DATA_PATH = os.path.join(DATA_PATH, 'val/')\r\n",
    "TEST_DATA_PATH = os.path.join(DATA_PATH, 'test/')"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T12:46:32.337984Z",
     "iopub.status.busy": "2021-08-12T12:46:32.337689Z",
     "iopub.status.idle": "2021-08-12T12:46:32.356540Z",
     "shell.execute_reply": "2021-08-12T12:46:32.355372Z",
     "shell.execute_reply.started": "2021-08-12T12:46:32.337954Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## reading the data "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def reading(path):\r\n",
    "    import glob as gb\r\n",
    "    x=[]\r\n",
    "    img_path=[]\r\n",
    "    label=[]\r\n",
    "    for folder in os.listdir(path ) :\r\n",
    "        files = gb.glob(pathname= str(path + folder +'/*.jpeg'))\r\n",
    "        x.append(files)\r\n",
    "        print(f'For passed data , found {len(files)} in folder {folder}')\r\n",
    "    normal=x[0]\r\n",
    "    pneumonia =x[1]\r\n",
    "    img_path=normal+pneumonia\r\n",
    "    for i in img_path :\r\n",
    "        if i in normal :\r\n",
    "            label.append(0)\r\n",
    "        else: \r\n",
    "            label.append(1) \r\n",
    "    return img_path,label\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## indexing the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def indexing(x):\r\n",
    "    \r\n",
    "    for i in x :\r\n",
    "        if i in normal :\r\n",
    "            label.append(0)\r\n",
    "        else: \r\n",
    "            label.append(1)   \r\n",
    "    return label"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## get the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def get(path):\r\n",
    "    x,y=reading(path)\r\n",
    "    print(len(x))\r\n",
    "    X=pd.Series(x)\r\n",
    "    Y=pd.Series(y)\r\n",
    "    return X , Y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "x1,y1=get(TRAIN_DATA_PATH)\r\n",
    "x2,y2=get(TEST_DATA_PATH)\r\n",
    "x3,y3=get(VAL_DATA_PATH)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For passed data , found 1341 in folder NORMAL\n",
      "For passed data , found 3875 in folder PNEUMONIA\n",
      "5216\n",
      "For passed data , found 234 in folder NORMAL\n",
      "For passed data , found 390 in folder PNEUMONIA\n",
      "624\n",
      "For passed data , found 8 in folder NORMAL\n",
      "For passed data , found 8 in folder PNEUMONIA\n",
      "16\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## reding and training validation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "\r\n",
    "df_train=pd.DataFrame(x1.append(x3),columns=['img_pass'])\r\n",
    "df_train['label']=pd.DataFrame(y1.append(y3))\r\n",
    "df_train.to_csv('train.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "df_test=pd.DataFrame(x2,columns=['img_pass'])\r\n",
    "df_test['label']=pd.DataFrame(y2)\r\n",
    "df_test.to_csv('test.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Your Pipeline of image transformation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Transformation\r\n",
    "TR = transforms.Compose(\r\n",
    "[transforms.Grayscale(CHANNELS),\r\n",
    "\r\n",
    "transforms.Resize(IMG_RESIZE)\r\n",
    ",transforms.ToTensor(),\r\n",
    "transforms.Normalize(mean=0.5,std=0.5)\r\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset Preparation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "trainset=datasets.ImageFolder(TRAIN_DATA_PATH,transform=TR)\r\n",
    "print(\"Trainset Size:  {}\".format(len(trainset)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Trainset Size:  5216\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "validateset=datasets.ImageFolder(VAL_DATA_PATH,transform=TR)\r\n",
    "print(\"validateset Size:  {}\".format(len(validateset)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "validateset Size:  16\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "testset=datasets.ImageFolder(TEST_DATA_PATH,transform=TR)\r\n",
    "print(\"testset Size:  {}\".format(len(testset)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "testset Size:  624\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "trainloader = DataLoader(trainset,batch_size=64,shuffle=True)\r\n",
    "print(\"No. of batches in trainloader:{}\".format(len(trainloader)))\r\n",
    "validationloader = DataLoader(validateset,batch_size=64,shuffle=True)\r\n",
    "print(\"No. of batches in validationloader:{}\".format(len(validationloader))) #validationset Size:  16 / batch_size: 16 = 1(No. of batches in validationloader) \r\n",
    "print(\"No. of Total examples:{}\".format(len(validationloader.dataset)))\r\n",
    "testloader = DataLoader(testset,batch_size=64,shuffle=True)\r\n",
    "print(\"No. of batches in testloader:{}\".format(len(testloader))) #testset Size:  624 / batch_size: 16 = 39(No. of batches in testloader) \r\n",
    "print(\"No. of Total examples:{}\".format(len(testloader.dataset)))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No. of batches in trainloader:82\n",
      "No. of batches in validationloader:1\n",
      "No. of Total examples:16\n",
      "No. of batches in testloader:10\n",
      "No. of Total examples:624\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "print(f\"Images in Training set: {df_train.shape[0]:,}\")\r\n",
    "print(f\"Images in Testing set: {df_test.shape[0]:,}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Images in Training set: 5,232\n",
      "Images in Testing set: 624\n"
     ]
    }
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T12:46:32.979653Z",
     "iopub.status.busy": "2021-08-12T12:46:32.979368Z",
     "iopub.status.idle": "2021-08-12T12:46:32.985310Z",
     "shell.execute_reply": "2021-08-12T12:46:32.984615Z",
     "shell.execute_reply.started": "2021-08-12T12:46:32.979624Z"
    },
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "len(df_train.img_pass)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5232"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "print(df_train.iloc[2][0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "C:/Users/20106/Desktop/Practical-DS-Session-main/Pneumonia/chest_xray/train/NORMAL\\IM-0119-0001.jpeg\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "df_train.sample(3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               img_pass  label\n",
       "1528  C:/Users/20106/Desktop/Practical-DS-Session-ma...      1\n",
       "2524  C:/Users/20106/Desktop/Practical-DS-Session-ma...      1\n",
       "1736  C:/Users/20106/Desktop/Practical-DS-Session-ma...      1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_pass</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>C:/Users/20106/Desktop/Practical-DS-Session-ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2524</th>\n",
       "      <td>C:/Users/20106/Desktop/Practical-DS-Session-ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>C:/Users/20106/Desktop/Practical-DS-Session-ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T12:46:34.365544Z",
     "iopub.status.busy": "2021-08-12T12:46:34.365010Z",
     "iopub.status.idle": "2021-08-12T12:46:34.387852Z",
     "shell.execute_reply": "2021-08-12T12:46:34.387109Z",
     "shell.execute_reply.started": "2021-08-12T12:46:34.365509Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "sns.countplot(df_train.label)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\20106\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "metadata": {},
     "execution_count": 23
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<svg height=\"291.167516pt\" version=\"1.1\" viewBox=\"0 0 433.585 291.167516\" width=\"433.585pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-08-29T23:11:22.565298</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.4.3, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 291.167516 \r\nL 433.585 291.167516 \r\nL 433.585 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 91.585 228.399078 \r\nL 426.385 228.399078 \r\nL 426.385 10.959078 \r\nL 91.585 10.959078 \r\nz\r\n\" style=\"fill:#eaeaf2;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(169.167969 253.646266)scale(0.22 -0.22)\">\r\n       <defs>\r\n        <path d=\"M 266 2259 \r\nQ 266 3072 433 3567 \r\nQ 600 4063 929 4331 \r\nQ 1259 4600 1759 4600 \r\nQ 2128 4600 2406 4451 \r\nQ 2684 4303 2865 4023 \r\nQ 3047 3744 3150 3342 \r\nQ 3253 2941 3253 2259 \r\nQ 3253 1453 3087 958 \r\nQ 2922 463 2592 192 \r\nQ 2263 -78 1759 -78 \r\nQ 1097 -78 719 397 \r\nQ 266 969 266 2259 \r\nz\r\nM 844 2259 \r\nQ 844 1131 1108 757 \r\nQ 1372 384 1759 384 \r\nQ 2147 384 2411 759 \r\nQ 2675 1134 2675 2259 \r\nQ 2675 3391 2411 3762 \r\nQ 2147 4134 1753 4134 \r\nQ 1366 4134 1134 3806 \r\nQ 844 3388 844 2259 \r\nz\r\n\" id=\"ArialMT-30\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"text_2\">\r\n      <!-- 1 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(336.567969 253.646266)scale(0.22 -0.22)\">\r\n       <defs>\r\n        <path d=\"M 2384 0 \r\nL 1822 0 \r\nL 1822 3584 \r\nQ 1619 3391 1289 3197 \r\nQ 959 3003 697 2906 \r\nL 697 3450 \r\nQ 1169 3672 1522 3987 \r\nQ 1875 4303 2022 4600 \r\nL 2384 4600 \r\nL 2384 0 \r\nz\r\n\" id=\"ArialMT-31\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-31\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_3\">\r\n     <!-- label -->\r\n     <g style=\"fill:#262626;\" transform=\"translate(233.633125 279.197516)scale(0.24 -0.24)\">\r\n      <defs>\r\n       <path d=\"M 409 0 \r\nL 409 4581 \r\nL 972 4581 \r\nL 972 0 \r\nL 409 0 \r\nz\r\n\" id=\"ArialMT-6c\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 2588 409 \r\nQ 2275 144 1986 34 \r\nQ 1697 -75 1366 -75 \r\nQ 819 -75 525 192 \r\nQ 231 459 231 875 \r\nQ 231 1119 342 1320 \r\nQ 453 1522 633 1644 \r\nQ 813 1766 1038 1828 \r\nQ 1203 1872 1538 1913 \r\nQ 2219 1994 2541 2106 \r\nQ 2544 2222 2544 2253 \r\nQ 2544 2597 2384 2738 \r\nQ 2169 2928 1744 2928 \r\nQ 1347 2928 1158 2789 \r\nQ 969 2650 878 2297 \r\nL 328 2372 \r\nQ 403 2725 575 2942 \r\nQ 747 3159 1072 3276 \r\nQ 1397 3394 1825 3394 \r\nQ 2250 3394 2515 3294 \r\nQ 2781 3194 2906 3042 \r\nQ 3031 2891 3081 2659 \r\nQ 3109 2516 3109 2141 \r\nL 3109 1391 \r\nQ 3109 606 3145 398 \r\nQ 3181 191 3288 0 \r\nL 2700 0 \r\nQ 2613 175 2588 409 \r\nz\r\nM 2541 1666 \r\nQ 2234 1541 1622 1453 \r\nQ 1275 1403 1131 1340 \r\nQ 988 1278 909 1158 \r\nQ 831 1038 831 891 \r\nQ 831 666 1001 516 \r\nQ 1172 366 1500 366 \r\nQ 1825 366 2078 508 \r\nQ 2331 650 2450 897 \r\nQ 2541 1088 2541 1459 \r\nL 2541 1666 \r\nz\r\n\" id=\"ArialMT-61\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 941 0 \r\nL 419 0 \r\nL 419 4581 \r\nL 981 4581 \r\nL 981 2947 \r\nQ 1338 3394 1891 3394 \r\nQ 2197 3394 2470 3270 \r\nQ 2744 3147 2920 2923 \r\nQ 3097 2700 3197 2384 \r\nQ 3297 2069 3297 1709 \r\nQ 3297 856 2875 390 \r\nQ 2453 -75 1863 -75 \r\nQ 1275 -75 941 416 \r\nL 941 0 \r\nz\r\nM 934 1684 \r\nQ 934 1088 1097 822 \r\nQ 1363 388 1816 388 \r\nQ 2184 388 2453 708 \r\nQ 2722 1028 2722 1663 \r\nQ 2722 2313 2464 2622 \r\nQ 2206 2931 1841 2931 \r\nQ 1472 2931 1203 2611 \r\nQ 934 2291 934 1684 \r\nz\r\n\" id=\"ArialMT-62\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 2694 1069 \r\nL 3275 997 \r\nQ 3138 488 2766 206 \r\nQ 2394 -75 1816 -75 \r\nQ 1088 -75 661 373 \r\nQ 234 822 234 1631 \r\nQ 234 2469 665 2931 \r\nQ 1097 3394 1784 3394 \r\nQ 2450 3394 2872 2941 \r\nQ 3294 2488 3294 1666 \r\nQ 3294 1616 3291 1516 \r\nL 816 1516 \r\nQ 847 969 1125 678 \r\nQ 1403 388 1819 388 \r\nQ 2128 388 2347 550 \r\nQ 2566 713 2694 1069 \r\nz\r\nM 847 1978 \r\nL 2700 1978 \r\nQ 2663 2397 2488 2606 \r\nQ 2219 2931 1791 2931 \r\nQ 1403 2931 1139 2672 \r\nQ 875 2413 847 1978 \r\nz\r\n\" id=\"ArialMT-65\" transform=\"scale(0.015625)\"/>\r\n      </defs>\r\n      <use xlink:href=\"#ArialMT-6c\"/>\r\n      <use x=\"22.216797\" xlink:href=\"#ArialMT-61\"/>\r\n      <use x=\"77.832031\" xlink:href=\"#ArialMT-62\"/>\r\n      <use x=\"133.447266\" xlink:href=\"#ArialMT-65\"/>\r\n      <use x=\"189.0625\" xlink:href=\"#ArialMT-6c\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_1\">\r\n      <path clip-path=\"url(#pe4e083fc62)\" d=\"M 91.585 228.399078 \r\nL 426.385 228.399078 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(69.850938 236.272672)scale(0.22 -0.22)\">\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_2\">\r\n      <path clip-path=\"url(#pe4e083fc62)\" d=\"M 91.585 121.736336 \r\nL 426.385 121.736336 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 2000 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(33.14875 129.60993)scale(0.22 -0.22)\">\r\n       <defs>\r\n        <path d=\"M 3222 541 \r\nL 3222 0 \r\nL 194 0 \r\nQ 188 203 259 391 \r\nQ 375 700 629 1000 \r\nQ 884 1300 1366 1694 \r\nQ 2113 2306 2375 2664 \r\nQ 2638 3022 2638 3341 \r\nQ 2638 3675 2398 3904 \r\nQ 2159 4134 1775 4134 \r\nQ 1369 4134 1125 3890 \r\nQ 881 3647 878 3216 \r\nL 300 3275 \r\nQ 359 3922 746 4261 \r\nQ 1134 4600 1788 4600 \r\nQ 2447 4600 2831 4234 \r\nQ 3216 3869 3216 3328 \r\nQ 3216 3053 3103 2787 \r\nQ 2991 2522 2730 2228 \r\nQ 2469 1934 1863 1422 \r\nQ 1356 997 1212 845 \r\nQ 1069 694 975 541 \r\nL 3222 541 \r\nz\r\n\" id=\"ArialMT-32\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-32\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"166.845703\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_3\">\r\n      <path clip-path=\"url(#pe4e083fc62)\" d=\"M 91.585 15.073594 \r\nL 426.385 15.073594 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 4000 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(33.14875 22.947187)scale(0.22 -0.22)\">\r\n       <defs>\r\n        <path d=\"M 2069 0 \r\nL 2069 1097 \r\nL 81 1097 \r\nL 81 1613 \r\nL 2172 4581 \r\nL 2631 4581 \r\nL 2631 1613 \r\nL 3250 1613 \r\nL 3250 1097 \r\nL 2631 1097 \r\nL 2631 0 \r\nL 2069 0 \r\nz\r\nM 2069 1613 \r\nL 2069 3678 \r\nL 634 1613 \r\nL 2069 1613 \r\nz\r\n\" id=\"ArialMT-34\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-34\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"166.845703\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_7\">\r\n     <!-- count -->\r\n     <g style=\"fill:#262626;\" transform=\"translate(24.37875 149.032203)rotate(-90)scale(0.24 -0.24)\">\r\n      <defs>\r\n       <path d=\"M 2588 1216 \r\nL 3141 1144 \r\nQ 3050 572 2676 248 \r\nQ 2303 -75 1759 -75 \r\nQ 1078 -75 664 370 \r\nQ 250 816 250 1647 \r\nQ 250 2184 428 2587 \r\nQ 606 2991 970 3192 \r\nQ 1334 3394 1763 3394 \r\nQ 2303 3394 2647 3120 \r\nQ 2991 2847 3088 2344 \r\nL 2541 2259 \r\nQ 2463 2594 2264 2762 \r\nQ 2066 2931 1784 2931 \r\nQ 1359 2931 1093 2626 \r\nQ 828 2322 828 1663 \r\nQ 828 994 1084 691 \r\nQ 1341 388 1753 388 \r\nQ 2084 388 2306 591 \r\nQ 2528 794 2588 1216 \r\nz\r\n\" id=\"ArialMT-63\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 213 1659 \r\nQ 213 2581 725 3025 \r\nQ 1153 3394 1769 3394 \r\nQ 2453 3394 2887 2945 \r\nQ 3322 2497 3322 1706 \r\nQ 3322 1066 3130 698 \r\nQ 2938 331 2570 128 \r\nQ 2203 -75 1769 -75 \r\nQ 1072 -75 642 372 \r\nQ 213 819 213 1659 \r\nz\r\nM 791 1659 \r\nQ 791 1022 1069 705 \r\nQ 1347 388 1769 388 \r\nQ 2188 388 2466 706 \r\nQ 2744 1025 2744 1678 \r\nQ 2744 2294 2464 2611 \r\nQ 2184 2928 1769 2928 \r\nQ 1347 2928 1069 2612 \r\nQ 791 2297 791 1659 \r\nz\r\n\" id=\"ArialMT-6f\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 2597 0 \r\nL 2597 488 \r\nQ 2209 -75 1544 -75 \r\nQ 1250 -75 995 37 \r\nQ 741 150 617 320 \r\nQ 494 491 444 738 \r\nQ 409 903 409 1263 \r\nL 409 3319 \r\nL 972 3319 \r\nL 972 1478 \r\nQ 972 1038 1006 884 \r\nQ 1059 663 1231 536 \r\nQ 1403 409 1656 409 \r\nQ 1909 409 2131 539 \r\nQ 2353 669 2445 892 \r\nQ 2538 1116 2538 1541 \r\nL 2538 3319 \r\nL 3100 3319 \r\nL 3100 0 \r\nL 2597 0 \r\nz\r\n\" id=\"ArialMT-75\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 422 0 \r\nL 422 3319 \r\nL 928 3319 \r\nL 928 2847 \r\nQ 1294 3394 1984 3394 \r\nQ 2284 3394 2536 3286 \r\nQ 2788 3178 2913 3003 \r\nQ 3038 2828 3088 2588 \r\nQ 3119 2431 3119 2041 \r\nL 3119 0 \r\nL 2556 0 \r\nL 2556 2019 \r\nQ 2556 2363 2490 2533 \r\nQ 2425 2703 2258 2804 \r\nQ 2091 2906 1866 2906 \r\nQ 1506 2906 1245 2678 \r\nQ 984 2450 984 1813 \r\nL 984 0 \r\nL 422 0 \r\nz\r\n\" id=\"ArialMT-6e\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 1650 503 \r\nL 1731 6 \r\nQ 1494 -44 1306 -44 \r\nQ 1000 -44 831 53 \r\nQ 663 150 594 308 \r\nQ 525 466 525 972 \r\nL 525 2881 \r\nL 113 2881 \r\nL 113 3319 \r\nL 525 3319 \r\nL 525 4141 \r\nL 1084 4478 \r\nL 1084 3319 \r\nL 1650 3319 \r\nL 1650 2881 \r\nL 1084 2881 \r\nL 1084 941 \r\nQ 1084 700 1114 631 \r\nQ 1144 563 1211 522 \r\nQ 1278 481 1403 481 \r\nQ 1497 481 1650 503 \r\nz\r\n\" id=\"ArialMT-74\" transform=\"scale(0.015625)\"/>\r\n      </defs>\r\n      <use xlink:href=\"#ArialMT-63\"/>\r\n      <use x=\"50\" xlink:href=\"#ArialMT-6f\"/>\r\n      <use x=\"105.615234\" xlink:href=\"#ArialMT-75\"/>\r\n      <use x=\"161.230469\" xlink:href=\"#ArialMT-6e\"/>\r\n      <use x=\"216.845703\" xlink:href=\"#ArialMT-74\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path clip-path=\"url(#pe4e083fc62)\" d=\"M 108.325 228.399078 \r\nL 242.245 228.399078 \r\nL 242.245 156.455059 \r\nL 108.325 156.455059 \r\nz\r\n\" style=\"fill:#5875a4;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path clip-path=\"url(#pe4e083fc62)\" d=\"M 275.725 228.399078 \r\nL 409.645 228.399078 \r\nL 409.645 21.313364 \r\nL 275.725 21.313364 \r\nz\r\n\" style=\"fill:#cc8963;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 91.585 228.399078 \r\nL 91.585 10.959078 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 426.385 228.399078 \r\nL 426.385 10.959078 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_7\">\r\n    <path d=\"M 91.585 228.399078 \r\nL 426.385 228.399078 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_8\">\r\n    <path d=\"M 91.585 10.959078 \r\nL 426.385 10.959078 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pe4e083fc62\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"91.585\" y=\"10.959078\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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"
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now given this high bias in our dataset ... we will fix it using 2 tricks ...\n",
    "  - weighted loss   \n",
    "  \n",
    "  so when our model **wrongly predict class 0** (the minority class) ... we **punish him more than** if he predicted class 1 wrong (the majority class)\n",
    "  - Balance the Evaluation dataset  \n",
    "  \n",
    "  we make our evalution dataset has same number of **class 0 and class 1** ... in-order to make the right decision when model has high accuracy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Weighted Loss"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "df_train.label.value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1    3883\n",
       "0    1349\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "x=3883+1349\r\n",
    "weight=torch.Tensor([3891,1341])/x\r\n",
    "criterion = nn.NLLLoss(weight= weight).to(DEVICE)\r\n",
    "print(criterion.weight)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0.7437, 0.2563])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "class Dataset():\r\n",
    "    from skimage import io\r\n",
    "    import cv2\r\n",
    "    def __init__(self, root_dir, transform=None):\r\n",
    "        \r\n",
    "        \r\n",
    "        self.root_dir = root_dir\r\n",
    "        self.transform = transform\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.root_dir)\r\n",
    "\r\n",
    "    def __getitem__(self, index):\r\n",
    "        img_path =self.root_dir.img_pass.iloc[index]\r\n",
    "        image=Image.open(img_path).convert(\"RGB\")\r\n",
    "        image = cv2.imread(img_path)\r\n",
    "\r\n",
    "        \r\n",
    "        y_label=self.root_dir.label.iloc[index]\r\n",
    "        #y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\r\n",
    "\r\n",
    "        image=self.transform(image)\r\n",
    "\r\n",
    "        return {\"image\":image.shape, \"label\":y_label}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "c=Dataset(df_train,TR)\r\n",
    "from skimage import io\r\n",
    "import cv2\r\n",
    "c"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<__main__.Dataset at 0x263352ea670>"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "train_loader = DataLoader(dataset=trainset, batch_size=64, shuffle=True)\r\n",
    "test_loader = DataLoader(dataset=testset, batch_size=64, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "class XrayClassifier(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.model = nn.Sequential(\r\n",
    "            nn.Conv2d(1, 32, padding=1, kernel_size=3),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(2),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Conv2d(32, 32, padding=1, kernel_size=3),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(2), \r\n",
    "            \r\n",
    "            nn.Conv2d(32, 64, padding=1, kernel_size=3),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Conv2d(64, 128, padding=1, kernel_size=3),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(2), \r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Conv2d(128, 128, padding=1, kernel_size=3),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(2), \r\n",
    "            \r\n",
    "            nn.Flatten(),\r\n",
    "            nn.Linear(128*15*21, 1024),\r\n",
    "            nn.Dropout(0.4),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(1024, 512),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(512, 128),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(128, 2)\r\n",
    "        )\r\n",
    "    \r\n",
    "    def forward(self, image):\r\n",
    "        return self.model(image)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "model=XrayClassifier()\r\n",
    "model"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "XrayClassifier(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU()\n",
       "    (9): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): ReLU()\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): ReLU()\n",
       "    (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU()\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Flatten(start_dim=1, end_dim=-1)\n",
       "    (17): Linear(in_features=40320, out_features=1024, bias=True)\n",
       "    (18): Dropout(p=0.4, inplace=False)\n",
       "    (19): ReLU()\n",
       "    (20): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (21): ReLU()\n",
       "    (22): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (23): ReLU()\n",
       "    (24): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "def to_device(data, device):\r\n",
    "    if isinstance(data, (list, tuple)):\r\n",
    "        return [to_device(x, device) for x in data]\r\n",
    "    return data.to(device, non_blocking=True)\r\n",
    "\r\n",
    "class DeviceDataLoader:\r\n",
    "    def __init__(self, dl, device):\r\n",
    "        self.dl = dl\r\n",
    "        self.device = device\r\n",
    "        \r\n",
    "    def __iter__(self):\r\n",
    "        for x in self.dl:\r\n",
    "            yield to_device(x, self.device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
    "device\r\n",
    "model = model.to(device)\r\n",
    "train_dl = DeviceDataLoader(train_loader, device)\r\n",
    "val_dl = DeviceDataLoader(validationloader, device)\r\n",
    "test_dl = DeviceDataLoader(testloader ,device)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "IMG_WIDTH = 224\r\n",
    "IMG_HEIGHT = 224\r\n",
    "CHANNELS = 1\r\n",
    "BS = 1 # Batch Size\r\n",
    "ex = torch.rand(BS, CHANNELS, IMG_WIDTH, IMG_HEIGHT)\r\n",
    "model = XrayClassifier()\r\n",
    "model.eval()\r\n",
    "out = model(ex)\r\n",
    "print(out.shape)\r\n",
    "out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Training method"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train_fn(batches, model, optim, scheduler, device=DEVICE):\r\n",
    "    model.train() # set the model mode => training\r\n",
    "    batch_acc = 0\r\n",
    "    ep_loss = 0\r\n",
    "    # Loop through the training batches\r\n",
    "    for batch in tqdm(batches, total=len(batches), position=0, leave=True):\r\n",
    "        \r\n",
    "        imgs, labels = # Get Your image and targets from the given batch\r\n",
    "        # Forward Propagation\r\n",
    "        labels_pred = ## Get Your predictions from model\r\n",
    "        # Calculate Loss\r\n",
    "        loss = ## Get your loss bet. Predictions and Targets\r\n",
    "        # Backward propagation (Check: https://discuss.pytorch.org/t/what-does-the-backward-function-do/9944)\r\n",
    "        ## - Zero your optimizer gradients\r\n",
    "        ## - Calculate loss gradient\r\n",
    "        ## - Make step with optimizer\r\n",
    "        ## - Accumulating Loss & Accuracy Across batches\r\n",
    "        ep_loss += loss.item()\r\n",
    "        batch_acc += sum(labels == labels_pred.argmax(1)).item()\r\n",
    "    # Calculate The whole Epoch Accuracy after the batches loop ends\r\n",
    "    ep_acc = batch_acc / (BATCH_SIZE * len(batches))\r\n",
    "    ## Return the ep_loss and the ep_acc\r\n",
    "    return ep_loss, ep_acc"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_11028/876353295.py, line 8)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\20106\\AppData\\Local\\Temp/ipykernel_11028/876353295.py\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    imgs, labels = # Get Your image and targets from the given batch\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T12:49:57.568701Z",
     "iopub.status.busy": "2021-08-12T12:49:57.568352Z",
     "iopub.status.idle": "2021-08-12T12:49:57.590431Z",
     "shell.execute_reply": "2021-08-12T12:49:57.589480Z",
     "shell.execute_reply.started": "2021-08-12T12:49:57.568669Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluation method"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def eval_fn(batches, model, device=DEVICE):\r\n",
    "    \"\"\"\r\n",
    "    Calculate the model accuracy & loss on given eval data ... no training is needed here\r\n",
    "    just prediction and comparing results\r\n",
    "    \"\"\"\r\n",
    "    ## Write your code here\r\n",
    "    return ep_loss, ep_acc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Prediction method"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def pred_fn(batches, model, device=DEVICE):\r\n",
    "    \"\"\"\r\n",
    "    Predict Test batches\r\n",
    "    Args:\r\n",
    "        batches (generator): Test Batches\r\n",
    "        model (model object): Trained Model\r\n",
    "        device (gpu/cpu device, optional): active device. Defaults to DEVICE.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "        predictions: List of predictions\r\n",
    "        true_labels: List of true labels\r\n",
    "    \"\"\"\r\n",
    "    ## Write your code here\r\n",
    "    return predictions, true_labels"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset Class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'image': (1144, 1450, 3), 'label': 0}"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1aaf36f7430>"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "            }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8220/4085992636.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTRAIN_DATA_PATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T13:11:06.701894Z",
     "iopub.status.busy": "2021-08-12T13:11:06.701366Z",
     "iopub.status.idle": "2021-08-12T13:11:06.710785Z",
     "shell.execute_reply": "2021-08-12T13:11:06.709718Z",
     "shell.execute_reply.started": "2021-08-12T13:11:06.701847Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'ClassificationModel' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14784/1687532174.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mClassificationModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ClassificationModel' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T13:12:50.543796Z",
     "iopub.status.busy": "2021-08-12T13:12:50.543314Z",
     "iopub.status.idle": "2021-08-12T13:12:50.556089Z",
     "shell.execute_reply": "2021-08-12T13:12:50.555346Z",
     "shell.execute_reply.started": "2021-08-12T13:12:50.543762Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Test your model with random input"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'XrayClassifier' object has no attribute 'conv1'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8220/2223094250.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXrayClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8220/3846033490.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_feauture\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m60\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mout_features\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernal_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mstride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1129\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1130\u001b[1;33m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[0;32m   1131\u001b[0m             type(self).__name__, name))\n\u001b[0;32m   1132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'XrayClassifier' object has no attribute 'conv1'"
     ]
    }
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T13:12:50.994779Z",
     "iopub.status.busy": "2021-08-12T13:12:50.994276Z",
     "iopub.status.idle": "2021-08-12T13:12:52.023365Z",
     "shell.execute_reply": "2021-08-12T13:12:52.022236Z",
     "shell.execute_reply.started": "2021-08-12T13:12:50.994747Z"
    },
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "k=datasets.ImageFolder(root=TRAIN_DATA_PATH)\r\n",
    "k"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 5216\n",
       "    Root location: C:/Users/20106/Desktop/Practical-DS-Session-main/Pneumonia/chest_xray/train/"
      ]
     },
     "metadata": {},
     "execution_count": 630
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split your Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torch.utils.data import WeightedRandomSampler\r\n",
    "sample_weights=[0]*len(df_train)\r\n",
    "for inx,(data,label) in enumerate(len(df_train)):\r\n",
    "    class_weight=riterion.weight[label]\r\n",
    "    sample_weights[inx]=class_weight\r\n",
    "sampler=WeightedRandomSampler(sample_weights, len(df_train))\r\n",
    "\r\n",
    "train_imgs, val_imgs, train_labels, val_labels = train_test_split(df_train.img_pass,df_train.label,test_size=0.20,random_state=42)\r\n",
    "\r\n",
    "print(f\"{len(train_imgs):,} Training imgs\")\r\n",
    "print(f\"{len(val_imgs):,} Validation imgs\")"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11028/2252438445.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWeightedRandomSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0minx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mriterion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msample_weights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "train_imgs, val_imgs, train_labels, val_labels = ## Write your code here\r\n",
    "\r\n",
    "print(f\"{len(train_imgs):,} Training imgs\")\r\n",
    "print(f\"{len(val_imgs):,} Validation imgs\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4,186 Training imgs\n",
      "1,046 Validation imgs\n"
     ]
    }
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T13:12:52.025492Z",
     "iopub.status.busy": "2021-08-12T13:12:52.025196Z",
     "iopub.status.idle": "2021-08-12T13:12:52.042419Z",
     "shell.execute_reply": "2021-08-12T13:12:52.041238Z",
     "shell.execute_reply.started": "2021-08-12T13:12:52.025462Z"
    },
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check Validation labels ... should be equal"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "val_labels.value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset instances for Train, Val & Test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_dataset = ## Write your code here\r\n",
    "val_dataset = ## Write your code here\r\n",
    "test_dataset = ## Write your code here"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T13:12:52.044021Z",
     "iopub.status.busy": "2021-08-12T13:12:52.043730Z",
     "iopub.status.idle": "2021-08-12T13:12:52.048428Z",
     "shell.execute_reply": "2021-08-12T13:12:52.047686Z",
     "shell.execute_reply.started": "2021-08-12T13:12:52.043993Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data-Loader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_batches = ## Write your code here\r\n",
    "val_batches = ## Write your code here\r\n",
    "test_batches = ## Write your code here"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T13:12:52.494250Z",
     "iopub.status.busy": "2021-08-12T13:12:52.493680Z",
     "iopub.status.idle": "2021-08-12T13:12:52.499272Z",
     "shell.execute_reply": "2021-08-12T13:12:52.498552Z",
     "shell.execute_reply.started": "2021-08-12T13:12:52.494198Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialize your model, optimizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "XrayClassifier()"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model =XrayClassifier(train_loader)\r\n",
    "optim =  torch.optim.Adam(model.parameters(), lr=0.001)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "__init__() takes 1 positional argument but 2 were given",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8220/3954662054.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mXrayClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0moptim\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T13:13:42.415715Z",
     "iopub.status.busy": "2021-08-12T13:13:42.415351Z",
     "iopub.status.idle": "2021-08-12T13:13:42.614076Z",
     "shell.execute_reply": "2021-08-12T13:13:42.613215Z",
     "shell.execute_reply.started": "2021-08-12T13:13:42.415682Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Create History For saving your losses and accuracies\r\n",
    "history= {}\r\n",
    "history['train_loss'] = []\r\n",
    "history['val_loss'] = []\r\n",
    "history['train_acc'] = []\r\n",
    "history['val_acc'] = []"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T13:13:42.989665Z",
     "iopub.status.busy": "2021-08-12T13:13:42.989327Z",
     "iopub.status.idle": "2021-08-12T13:13:43.001959Z",
     "shell.execute_reply": "2021-08-12T13:13:43.000905Z",
     "shell.execute_reply.started": "2021-08-12T13:13:42.989634Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training Loop"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for epoch in range(EPOCHS):\r\n",
    "        s = time()\r\n",
    "        # train\r\n",
    "        ep_train_loss, ep_train_acc = train_fn(train_batches, model, optim, scheduler)\r\n",
    "        # eval\r\n",
    "        ep_val_loss, ep_val_acc = eval_fn(val_batches, model)\r\n",
    "        e = time()\r\n",
    "\r\n",
    "        epoch_t = remainig_time(e - s)\r\n",
    "        whole_time = remainig_time((e - s) * (EPOCHS - epoch))\r\n",
    "        print(f\"\\nEpoch:{epoch}/{EPOCHS}---Loss-train:{ep_train_loss:.4f}---Loss-Val: {ep_val_loss:.4f}---Acc-Train:{(ep_train_acc*100):.2f}%---Acc-Val: {(ep_val_acc*100):.2f}%---Acc-Test: {(ep_test_acc*100):.2f}---%epoch elapsed:{epoch_t}---Remaining:{whole_time}\")\r\n",
    "        \r\n",
    "        ## Write your code here ## append the training loss\r\n",
    "        ## Write your code here ## append the validation loss\r\n",
    "        ## Write your code here ## append the training acc\r\n",
    "        ## Write your code here ## append the validation acc\r\n",
    "\r\n",
    "        if ep_val_acc > MIN_ACC:\r\n",
    "            print(\"Saving Model ...\")\r\n",
    "            model_name = f'Xray_ep_{epoch}_acc_{(ep_test_acc*100):.3f}_.pth'\r\n",
    "            MIN_ACC = ep_test_acc\r\n",
    "            # Save Your model Checkpoint\r\n",
    "            ## Write your code here"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T13:13:44.146411Z",
     "iopub.status.busy": "2021-08-12T13:13:44.145920Z",
     "iopub.status.idle": "2021-08-12T13:14:35.168955Z",
     "shell.execute_reply": "2021-08-12T13:14:35.167503Z",
     "shell.execute_reply.started": "2021-08-12T13:13:44.146378Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "MODEL_PATH = '' # Get your model path\r\n",
    "checkpoint = load_model(MODEL_PATH)\r\n",
    "model.load_state_dict(checkpoint['model_state_dict']) # Just loading the model weights"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preds, labels = pred_fn(test_batches, model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(f\"Accuracy: {(np.array(preds) == np.array(labels)).mean()*100:.1f}% On Test Set\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(classification_report(labels, preds, target_names=CLASSES))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a confusion matrix and plot it"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Write your code here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Great Work ... 💪💪"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now you're able to get and start applying your various types of ***DL approches*** and ***compete with many Kagglers***\n",
    "There exist huge amount of images data out there ... that you're now able to give it a try and apply your own model on ... Good Start 👍👍😊"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "interpreter": {
   "hash": "3f8f5e4626f6ab8d0c196c87ac1f7e85762bc25247b3a3f413265d610a607eb2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}